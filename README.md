# Awesome-motion

An aggregation of human motion understanding researches, trying my best to be comprehensive and up-to-date.

## Motion Generation

- [Text to blind motion](https://nips.cc/virtual/2024/poster/97700) NeurIPS D&B 2024.
- [MoMu-Diffusion](https://momu-diffusion.github.io/) NeurIPS 2024.
- [MoGenTS](https://aigc3d.github.io/mogents/) NeurIPS 2024.
- [M3GPT](https://arxiv.org/abs/2405.16273) NeurIPS 2024.
- [Jin et al.](https://jpthu17.github.io/GuidedMotion-project/) ECCV 2024.
- [Motion Mamba](https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/100_ECCV_2024_paper.php) ECCV 2024.
- [EMDM](https://frank-zy-dou.github.io/projects/EMDM/index.html) ECCV 2024.
- [CoMo](https://yh2371.github.io/como/) ECCV 2024.
- [CoMusion](https://github.com/jsun57/CoMusion) ECCV 2024.
- [Shan et al.](https://arxiv.org/abs/2405.18483) ECCV 2024.
- [ParCo](https://github.com/qrzou/ParCo) ECCV 2024.
- [Sampieri et al.](https://arxiv.org/abs/2407.11532) ECCV 2024.
- [ChroAccRet](https://github.com/line/ChronAccRet) ECCV 2024.
- [MHC](https://idigitopia.github.io/projects/mhc/) ECCV 2024.
- [ProMotion](https://github.com/moonsliu/Pro-Motion) ECCV 2024.
- [FreeMotion](https://arxiv.org/abs/2406.10740) ECCV 2024.
- [Text Motion Translator](https://eccv.ecva.net/virtual/2024/poster/266) ECCV 2024.
- [FreeMotion](https://vankouf.github.io/FreeMotion/) ECCV 2024.
- [Kinematic Phrases](https://foruck.github.io/KP/) ECCV 2024.
- [MotionChain](https://arxiv.org/abs/2404.01700) ECCV 2024.
- [SMooDi](https://neu-vi.github.io/SMooDi/) ECCV 2024.
- [BAMM](https://exitudio.github.io/BAMM-page/) ECCV 2024.
- [MotionLCM](https://dai-wenxun.github.io/MotionLCM-page/) ECCV 2024.
- [Ren et al.](https://arxiv.org/abs/2312.10993) ECCV 2024.
- [M2D2M](https://arxiv.org/abs/2407.14502) ECCV 2024.
- [Large Motion Model](https://mingyuan-zhang.github.io/projects/LMM.html) ECCV 2024.
- [TesMo](https://research.nvidia.com/labs/toronto-ai/tesmo/) ECCV 2024.
- [TLcontrol](https://tlcontrol.weilinwl.com/) ECCV 2024.
- [HumanTOMATO](https://github.com/LinghaoChan/HumanTOMATO) ICML 2024.
- [GPHLVM](https://sites.google.com/view/gphlvm/) ICML 2024.
- [CondMDI](https://setarehc.github.io/CondMDI/) SIGGRAPH 2024.
- [LGTM](https://vcc.tech/research/2024/LGTM) SIGGRAPH 2024.
- [TEDi](https://threedle.github.io/TEDi/) SIGGRAPH 2024.
- [A-MDM](https://github.com/Yi-Shi94/AMDM) SIGGRAPH 2024.
- [SuperPADL](https://arxiv.org/abs/2407.10481) SIGGRAPH 2024.
- [ProgMoGen](https://github.com/HanchaoLiu/ProgMoGen) CVPR 2024.
- [PACER+](https://github.com/IDC-Flash/PacerPlus) CVPR 2024.
- [AMUSE](https://amuse.is.tue.mpg.de/) CVPR 2024.
- [Liu et al.](https://github.com/feifeifeiliu/probtalk) CVPR 2024.
- [MAS](https://guytevet.github.io/mas-page/) CVPR 2024.
- [WANDR](https://wandr.is.tue.mpg.de/) CVPR 2024.
- [MoMask](https://ericguo5513.github.io/momask/) CVPR 2024.
- [ChapPose](https://yfeng95.github.io/ChatPose/) CVPR 2024.
- [AvatarGPT](https://zixiangzhou916.github.io/AvatarGPT/) CVPR 2024.
- [MMM](https://exitudio.github.io/MMM-page/) CVPR 2024.
- [AAMDM](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_AAMDM_Accelerated_Auto-regressive_Motion_Diffusion_Model_CVPR_2024_paper.pdf) CVPR 2024.
- [OMG](https://tr3e.github.io/omg-page/) CVPR 2024.
- [FlowMDM](https://barquerogerman.github.io/FlowMDM/) CVPR 2024.
- [Digital Life Project](https://digital-life-project.com/) CVPR 2024.
- [Single Motion Diffusion](https://sinmdm.github.io/SinMDM-page/) ICLR 2024.
- [NeRM](https://openreview.net/forum?id=sOJriBlOFd&noteId=KaJUBoveeo) ICLR 2024.
- [PriorMDM](https://priormdm.github.io/priorMDM-page/) ICLR 2024.
- [OmniControl](https://neu-vi.github.io/omnicontrol/) ICLR 2024.
- [Adiya et al.](https://openreview.net/forum?id=yQDFsuG9HP) ICLR 2024.
- [HuTuDiffusion](https://arxiv.org/abs/2312.12227) AAAI 2024.
- [AMD](https://arxiv.org/abs/2312.12763) AAAI 2024.
- [Xie et al.](https://arxiv.org/pdf/2312.12917) WACV 2023.
- [GraphMotion](https://github.com/jpthu17/GraphMotion) NeurIPS 2023.
- [MotionGPT](https://github.com/OpenMotionLab/MotionGPT) NeurIPS 2023.
- [FineMoGen](https://mingyuan-zhang.github.io/projects/FineMoGen.html) NeurIPS 2023.
- [InsActor](https://jiawei-ren.github.io/projects/insactor/) NeurIPS 2023.
- [AttT2M](https://github.com/ZcyMonkey/AttT2M) ICCV 2023.
- [TMR](https://mathis.petrovich.fr/tmr) ICCV 2023.
- [MAA](https://azadis.github.io/make-an-animation) ICCV 2023.
- [PhysDiff](https://nvlabs.github.io/PhysDiff) ICCV 2023.
- [ReMoDiffusion](https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html) ICCV 2023.
- [GMD](https://korrawe.github.io/gmd-project/) ICCV 2023.
- [HMD-NeMo](https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html) ICCV 2023.
- [SINC](https://sinc.is.tue.mpg.de/) ICCV 2023.
- [Kong et al.](https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.html) ICCV 2023.
- [FgT2M](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.html) ICCV 2023.
- [EMS](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.html) ICCV 2023.
- [GenMM](https://weiyuli.xyz/GenMM/) SIGGRAPH 2023.
- [GestureDiffuCLIP](https://pku-mocca.github.io/GestureDiffuCLIP-Page/) SIGGRAPH 2023.
- [Pang et al.](https://i.cs.hku.hk/~taku/kunkun2023.pdf) SIGGRAPH 2023.
- [Alexanderson et al.](https://www.speech.kth.se/research/listen-denoise-action/) SIGGRAPH 2023.
- [AGroL](https://dulucas.github.io/agrol/) CVPR 2023.
- [TALKSHOW](https://talkshow.is.tue.mpg.de/) CVPR 2023.
- [T2M-GPT](https://mael-zys.github.io/T2M-GPT/) CVPR 2023.
- [UDE](https://zixiangzhou916.github.io/UDE/) CVPR 2023.
- [OOHMG](https://github.com/junfanlin/oohmg) CVPR 2023.
- [MLD](https://chenxin.tech/mld) CVPR 2023.
- [MoDi](https://sigal-raab.github.io/MoDi) CVPR 2023.
- [MoFusion](https://vcai.mpi-inf.mpg.de/projects/MoFusion/) CVPR 2023.
- [Mo et al.](https://arxiv.org/abs/2303.14926) CVPR 2023.
- [HMDM](https://guytevet.github.io/mdm-page/) ICLR 2023.
- [UDE-2](https://zixiangzhou916.github.io/UDE-2/) ArXiv 2023.
- [Motion Script](https://pjyazdian.github.io/MotionScript/) ArXiv 2023.
- [NeMF](https://github.com/c-he/NeMF) NeurIPS 2022.
- [PADL](https://github.com/nv-tlabs/PADL) SIGGRAPH Asia 2022.
- [Rhythmic Gesticulator](https://pku-mocca.github.io/Rhythmic-Gesticulator-Page/) SIGGRAPH Asia 2022.
- [Implicit Motion](https://github.com/PACerv/ImplicitMotion) ECCV 2022.
- [Zhong et al.](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136810707.pdf) ECCV 2022.
- [MotionCLIP](https://guytevet.github.io/motionclip-page/) ECCV 2022.
- [PoseGPT](https://europe.naverlabs.com/research/computer-vision/posegpt) ECCV 2022.
- [TEMOS](https://mathis.petrovich.fr/temos/) ECCV 2022.
- [TM2T](https://ericguo5513.github.io/TM2T/) ECCV 2022.
- [Guo et al.](https://ericguo5513.github.io/text-to-motion) CVPR 2022

## Motion Editing

- [CigTime](https://btekin.github.io/) NeurIPS 2024.
- [Iterative Motion Editing](iterative-motion-editing) SIGGRAPH 2024.
- [DNO](https://korrawe.github.io/dno-project/) CVPR 2024.

## Motion Stylization

- [HUMOS](https://otaheri.github.io/publication/2024_humos/) ECCV 2024.
- [SMEAR](https://dl.acm.org/doi/10.1145/3641519.3657457) SIGGRAPH 2024.
- [MCM-LDM](https://xingliangjin.github.io/MCM-LDM-Web/) CVPR 2024.
- [MoST](https://boeun-kim.github.io/page-MoST/) CVPR 2024.
- [GenMoStyle](https://yxmu.foo/GenMoStyle/) ICLR 2024.

## Human-Object Interaction

- [HumanVLA](https://arxiv.org/abs/2406.19972) NeurIPS 2024.
- [OmniGrasp](https://www.zhengyiluo.com/Omnigrasp-Site/) NeurIPS 2024.
- [EgoChoir](https://yyvhang.github.io/EgoChoir/) NeurIPS 2024.
- [CooHOI](https://gao-jiawei.com/Research/CooHOI/) NeurIPS 2024.
- [InterDreamer](https://arxiv.org/abs/2403.19652) NeurIPS 2024.
- [InterFusion](https://sisidai.github.io/InterFusion/) ECCV 2024.
- [CHOIS](https://lijiaman.github.io/projects/chois/) ECCV 2024.
- [F-HOI](https://f-hoi.github.io/) ECCV 2024.
- [HIMO](https://lvxintao.github.io/himo/) ECCV 2024.
- [PhysicsPingPong](https://jiashunwang.github.io/PhysicsPingPong/) SIGGRPAH 2024.
- [NIFTY](https://nileshkulkarni.github.io/nifty/) CVPR 2024.
- [HOI Animator](https://zxylinkstart.github.io/HOIAnimator-Web/) CVPR 2024.
- [CG-HOI](https://cg-hoi.christian-diller.de/#main) CVPR 2024.
- [Text2HOI](https://github.com/JunukCha/Text2HOI) CVPR 2024.
- [OMOMO](https://github.com/lijiaman/omomo_release) SIGGRAPH Asia 2023.
- [CHAIRS](https://jnnan.github.io/project/chairs/) ICCV 2023.
- [HGHOI](https://zju3dv.github.io/hghoi) ICCV 2023.
- [InterDiff](https://sirui-xu.github.io/InterDiff/) ICCV 2023.
- [Object Pop Up](https://virtualhumans.mpi-inf.mpg.de/object_popup/) CVPR 2023.
- [TOCH](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136630001.pdf) ECCV 2022.
- [GOAL](https://goal.is.tue.mpg.de/) CVPR 2022.

## Human-Scene Interaction

- [Lou et al.]([https://neurips.cc/virtual/2024/poster/95438](https://sites.google.com/view/dimop3d)) NeurIPS 2024.
- [Liu et al.](https://arxiv.org/html/2312.02700v2) ECCV 2024.
- [Afford-Motion](https://afford-motion.github.io/) CVPR 2024.
- [GenZI](https://craigleili.github.io/projects/genzi/) CVPR 2024.
- [Cen et al.](https://zju3dv.github.io/text_scene_motion/) CVPR 2024.
- [TRUMANS](https://github.com/jnnan/trumans_utils) CVPR 2024.
- [UniHSI](https://xizaoqu.github.io/unihsi/) ICLR 2024.
- [DIMOS](https://github.com/zkf1997/DIMOS) ICCV 2023.
- [LAMA](https://jiyewise.github.io/projects/LAMA/) ICCV 2023.
- [Narrator](http://cic.tju.edu.cn/faculty/likun/projects/Narrator) ICCV 2023.
- [CIMI4D](http://www.lidarhumanmotion.net/cimi4d) CVPR 2023.
- [Scene-Ego](https://people.mpi-inf.mpg.de/~jianwang/projects/sceneego/) CVPR 2023.
- [SLOPER4D](http://www.lidarhumanmotion.net/sloper4d) CVPR 2023.
- [CIRCLE](https://stanford-tml.github.io/circle_dataset/) CVPR 2023.
- [PMP](https://github.com/jinseokbae/pmp) SIGGRAPH 2023.
- [Hassan et al.](https://research.nvidia.com/publication/2023-08_synthesizing-physical-character-scene-interactions) SIGGRAPH 2023.
- [Li et al.](https://changyangli.github.io/assets/paper/sig23snippet.pdf) SIGGRAPH 2023.
- [Mao et al.](https://github.com/wei-mao-2019/ContAwareMotionPred) NeurIPS 2022.
- [HUMANISE](https://github.com/Silverster98/HUMANISE) NeurIPS 2022.
- [EmbodiedPose](https://github.com/ZhengyiLuo/EmbodiedPose) NeurIPS 2022.
- [GIMO](https://github.com/y-zheng18/GIMO) ECCV 2022.
- [Wang et al.](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.pdf) CVPR 2022.
- [PROX](https://prox.is.tue.mpg.de/) ICCV 2019

## Human-Human Interaction

- [InterControl](https://github.com/zhenzhiwang/intercontrol) NeurIPS 2024.
- [ReMoS](https://github.com/anindita127/ReMoS) ECCV 2024.
- [Inter-X](https://liangxuy.github.io/inter-x/) CVPR 2024.
- [ReGenNet](https://github.com/liangxuy/ReGenNet) CVPR 2024.
- [Fang et al.](https://openaccess.thecvf.com/content/CVPR2024/papers/Fang_Capturing_Closely_Interacted_Two-Person_Motions_with_Reaction_Priors_CVPR_2024_paper.pdf) CVPR 2024.
- [ActFormer](https://liangxuy.github.io/actformer/) ICCV 2023.
- [Tanaka et al.](https://github.com/line/Human-Interaction-Generation) ICCV 2023.
- [Hi4D](https://yifeiyin04.github.io/Hi4D/) CVPR 2023.

## Datasets

- [EgoSim](https://nips.cc/virtual/2024/poster/97590) NeurIPS D&B 2024.
- [Muscles in Time](https://arxiv.org/abs/2411.00128) NeurIPS D&B 2024.
- [Text to blind motion](https://nips.cc/virtual/2024/poster/97700) NeurIPS D&B 2024.
- [MotionBank](https://github.com/liangxuy/MotionBank) ArXiv 2024.
- [AddBiomechanics](https://addbiomechanics.org/) ECCV 2024.
- [LiveHPS++](LiveHPS++) ECCV 2024.
- [SignAvatars](https://signavatars.github.io/) ECCV 2024.
- [Nymeria](https://www.projectaria.com/datasets/nymeria) ECCV 2024.
- [Inter-X](https://liangxuy.github.io/inter-x/) CVPR 2024.
- [HardMo](https://openaccess.thecvf.com/content/CVPR2024/papers/Liao_HardMo_A_Large-Scale_Hardcase_Dataset_for_Motion_Capture_CVPR_2024_paper.pdf) CVPR 2024.
- [RELI11D](http://www.lidarhumanmotion.net/reli11d/) CVPR 2024.
- [HOH](https://hohdataset.github.io/) NeurIPS D&B 2023.
- [Motion-X](https://motion-x-dataset.github.io/) NeurIPS D&B 2023.
- [Humans in Kitchens](https://github.com/jutanke/hik) NeurIPS D&B 2023.
- [CHAIRS](https://jnnan.github.io/project/chairs/) ICCV 2023.
- [CIMI4D](http://www.lidarhumanmotion.net/cimi4d) CVPR 2023.
- [Hi4D](https://yifeiyin04.github.io/Hi4D/) CVPR 2023.
- [CIRCLE](https://stanford-tml.github.io/circle_dataset/) CVPR 2023.
- [MoCapAct](https://github.com/microsoft/MoCapAct) NeurIPS 2022.
- [BEAT](https://pantomatrix.github.io/BEAT/) ECCV 2022.
- [BRACE](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680321.pdf) ECCV 2022.
- [EgoBody](https://sanweiliti.github.io/egobody/egobody.html) ECCV 2022.
- [GIMO](https://github.com/y-zheng18/GIMO) ECCV 2022.
- [UnrealEgo](https://4dqv.mpi-inf.mpg.de/UnrealEgo/) ECCV 2022.
- [Guo et al.](https://ericguo5513.github.io/text-to-motion) CVPR 2022
- [BABEL](https://babel.is.tue.mpg.de/) CVPR 2021
- [PROX](https://prox.is.tue.mpg.de/) ICCV 2019
- [AMASS](https://amass.is.tue.mpg.de/) ICCV 2019

## Humanoid, Simulated or Real

- [HumanVLA](https://arxiv.org/abs/2406.19972) NeurIPS 2024.
- [OmniGrasp](https://www.zhengyiluo.com/Omnigrasp-Site/) NeurIPS 2024.
- [CooHOI](https://gao-jiawei.com/Research/CooHOI/) NeurIPS 2024.
- [Radosavovic et al.](https://humanoid-next-token-prediction.github.io/) NeurIPS 2024.
- [DynSyn](https://www.beanpow.top/assets/pdf/dynsyn_poster.pdf) ICML 2024.
- [MoConVQ](https://github.com/heyuanYao-pku/MoConVQ) SIGGRAPH 2024.
- [CAMDM](https://aiganimation.github.io/CAMDM/) SIGGRAPH 2024.
- [PhysicsPingPong](https://jiashunwang.github.io/PhysicsPingPong/) SIGGRPAH 2024.
- [SuperPADL](https://arxiv.org/abs/2407.10481) SIGGRAPH 2024.
- [Starke et al.](https://dl.acm.org/doi/10.1145/3658209) SIGGRAPH 2024.
- [PULSE](https://github.com/ZhengyiLuo/PULSE) ICLR 2024.
- [H-GAP](https://github.com/facebookresearch/hgap) ICLR 2024.
- [UniHSI](https://xizaoqu.github.io/unihsi/) ICLR 2024.
- [MuscleVAE](https://pku-mocca.github.io/MuscleVAE-page/) SIGGRAPH Asia 2023.
- [CASE](https://frank-zy-dou.github.io/projects/CASE/index.html) SIGGRAPH Asia 2023.
- [AdaptNet](https://github.com/xupei0610/AdaptNet) SIGGRAPH Asia 2023.
- [NCP](https://tencent-roboticsx.github.io/NCP/) SIGGRAPH Asia 2023.
- [DROP](https://stanford-tml.github.io/drop/) SIGGRAPH Asia 2023.
- [InsActor](https://jiawei-ren.github.io/projects/insactor/) NeurIPS 2023.
- [PHC](https://zhengyiluo.github.io/PHC/) ICCV 2023.
- [DiffMimic](https://diffmimic.github.io/) ICLR 2023.
- [Vid2Player3D](https://research.nvidia.com/labs/toronto-ai/vid2player3d/) SIGGRAPH 2023.
- [Xu et al.](https://arxiv.org/abs/2305.03286) SIGGRAPH 2023.
- [Bidirectional GaitNet](https://github.com/namjohn10/BidirectionalGaitNet) SIGGRAPH 2023.
- [Lee et al.](https://arxiv.org/abs/2305.04995) SIGGRAPH 2023.
- [EmbodiedPose](https://github.com/ZhengyiLuo/EmbodiedPose) NeurIPS 2022.
- [MoCapAct](https://github.com/microsoft/MoCapAct) NeurIPS 2022.
- [Gopinath et al.](https://research.facebook.com/publications/motion-in-betweening-for-physically-simulated-characters/) SIGGRAPH Asia 2022.
- [AIP](https://dl.acm.org/doi/10.1145/3550082.3564207) SIGGRAPH Asia 2022.
- [QuestSim](https://dl.acm.org/doi/fullHtml/10.1145/3550469.3555411) SIGGRAPH Asia 2022.
- [PADL](https://github.com/nv-tlabs/PADL) SIGGRAPH Asia 2022.
- [Wang et al.](https://dl.acm.org/doi/10.1145/3550454.3555490) SIGGRAPH Asia 2022.
